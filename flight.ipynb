{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "DATASET_PATH = \"D:/flight dataset/\"\n",
    "\n",
    "intr_cols = [\n",
    "    \"Origin\", \"Dest\", \"Cancelled\", \"DepTime\",\n",
    "    \"DepDelayMinutes\", \"Distance\", \"Month\", \"DayofMonth\",\n",
    "    \"DayOfWeek\", \"DOT_ID_Operating_Airline\", \"Tail_Number\", \"Flight_Number_Operating_Airline\",\n",
    "    \"WheelsOff\", \"TaxiOut\",\n",
    "    \"Year\",\n",
    "    #\"FlightDate\",\n",
    "    #\"Diverted\",\n",
    "    #\"ArrTime\",\n",
    "    #\"ArrDelayMinutes\",\n",
    "    #\"AirTime\",\n",
    "    #\"ActualElapsedTime\",\n",
    "    #\"Operating_Airline\",\n",
    "    #\"OriginCityName\",\n",
    "    #\"OriginStateName\",\n",
    "    #\"OriginWac\",\n",
    "    #\"DestCityName\",\n",
    "    #\"DestStateName\",\n",
    "    #\"DestWac\",\n",
    "    #\"WheelsOn\",\n",
    "    #\"Airline\",\n",
    "    #\"TaxiIn\",\n",
    "    #\"DivAirportLandings\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "# Load all dataframes\n",
    "def loadAll(lstFiles, lstCol=intr_cols):\n",
    "    if type(lstFiles) != list:\n",
    "        lstFiles = [lstFiles]\n",
    "    df = pd.DataFrame({})\n",
    "    for dataFile in tqdm(lstFiles):\n",
    "        dfTemp = pd.read_csv(DATASET_PATH + dataFile)\n",
    "        dfTemp = dfTemp[lstCol]\n",
    "        df = pd.concat([df, dfTemp], ignore_index=True)\n",
    "        del dfTemp\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "\n",
    "# Correlation plot\n",
    "def plotCorr(df):\n",
    "    plt.figure(figsize=(11,8))\n",
    "    sns.heatmap(df.corr(), annot=True)\n",
    "    #sns.pairplot(df)\n",
    "    plt.show()\n",
    "\n",
    "# BAR PLOT: delays\n",
    "def plotDelayType(df, title):\n",
    "    onTimeDf = df.query(\"DepDelayMinutes == 0\").size\n",
    "    smallDelay = df.query(\"DepDelayMinutes > 0 & DepDelayMinutes <= 15\").size\n",
    "    mediumDelay = df.query(\"DepDelayMinutes > 15  & DepDelayMinutes <= 30\").size\n",
    "    largeDelay = df.query(\"DepDelayMinutes > 30\").size\n",
    "\n",
    "    plt.bar([\"On Time\", \"Small Delay\", \"Medium Delay\", \"Large Delay\"], [onTimeDf, smallDelay, mediumDelay, largeDelay], color = [\"purple\", \"violet\", \"slateblue\", \"royalblue\"])\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# BAR PLOT: Average Delay by Week\n",
    "def weeklyDelay(df, title):\n",
    "    daily = []\n",
    "    weekRange = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "\n",
    "    for x in range(1, len(weekRange) + 1):\n",
    "        dailyDf = df.query(f\"DayOfWeek == {x}\")\n",
    "        daily.append(dailyDf[\"DepDelayMinutes\"].sum() / dailyDf.size)\n",
    "\n",
    "    plt.bar(weekRange, daily, color = [\"springgreen\", \"lightgreen\", \"mediumseagreen\", \"limegreen\", \"seagreen\",  \"forestgreen\",  \"darkgreen\"])\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# State Delay Chart\n",
    "def plotStateDelay(df, title):\n",
    "    groupDf = df[[\"DepDelayMinutes\", \"OriginStateName\"]].groupby([\"OriginStateName\"])\n",
    "    joined = groupDf.sum().merge(groupDf.size().rename(\"size\"), left_index=True, right_index=True)\n",
    "    avgDelState = joined[\"DepDelayMinutes\"] / joined[\"size\"]\n",
    "    avgDelState = avgDelState.sort_values(ascending=True)\n",
    "    plt.figure(figsize=(5,10))\n",
    "    avgDelState.plot.barh(color=\"teal\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loadAll(\"Combined_Flights_2018.csv\")\n",
    "df.drop(\"Cancelled\", axis=1, inplace=True)\n",
    "plotCorr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstCol = [\"DepDelayMinutes\", \"DayOfWeek\", \"OriginStateName\"]\n",
    "files = [\"Combined_Flights_2018.csv\", \"Combined_Flights_2019.csv\", \"Combined_Flights_2021.csv\", \"Combined_Flights_2022.csv\"]\n",
    "df2020 = loadAll(\"Combined_Flights_2020.csv\", lstCol)\n",
    "df = loadAll(files, lstCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDelayType(df, \"Type of Delay\\n2020 excluded\")\n",
    "plotDelayType(df2020, \"Type of Delay 2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeklyDelay(df, \"Average Delay by Week\\n2020 excluded\")\n",
    "weeklyDelay(df2020, \"Average Delay by Week 2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotStateDelay(df, \"States Delay chart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preprocessing\n",
    "files = [\"Combined_Flights_2018.csv\", \"Combined_Flights_2019.csv\", \"Combined_Flights_2020.csv\", \"Combined_Flights_2021.csv\", \"Combined_Flights_2022.csv\"]\n",
    "df = loadAll(files, intr_cols)\n",
    "\n",
    "# Remove cancelled flight\n",
    "df = df[df[\"Cancelled\"] == False].drop(\"Cancelled\", axis=1, inplace=False)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Encode str to int32 \n",
    "leAirport = LabelEncoder()\n",
    "leTail = LabelEncoder()\n",
    "leAirport.fit(np.unique(df[[\"Origin\", \"Dest\"]].values.reshape(1, -1)))\n",
    "df[\"Origin\"] = leAirport.transform(df[\"Origin\"])\n",
    "df[\"Dest\"] = leAirport.transform(df[\"Dest\"])\n",
    "df[\"Tail_Number\"] = leTail.fit_transform(df[\"Tail_Number\"])\n",
    "\n",
    "# Encode delayed result\n",
    "df[\"DepDelayMinutes\"] = (df[\"DepDelayMinutes\"] > 15).astype(\"int\")\n",
    "\n",
    "# Track 2020\n",
    "df[\"Year\"] = df[\"Year\"] == 2020\n",
    "sample_weight = df[\"Year\"].values\n",
    "df.drop(\"Year\", inplace=False, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "y = df[\"DepDelayMinutes\"].values\n",
    "X = df.drop(\"DepDelayMinutes\", inplace=False, axis = 1).values\n",
    "features_name = list(df.drop(\"DepDelayMinutes\", inplace=False, axis = 1).columns.values)\n",
    "del df\n",
    "X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(X, y, sample_weight, test_size = 0.25, random_state = 0)\n",
    "# Scaling values\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression model\n",
    "lstReport = {}\n",
    "for w in tqdm(np.linspace(0, 1, 10)):\n",
    "    classifier = LogisticRegression(solver=\"saga\", random_state=0, n_jobs=-1)\n",
    "    sw_train_temp = (sw_train * w) + (sw_train == 0)\n",
    "    classifier = classifier.fit(X_train, y_train, sample_weight=sw_train_temp)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    lstReport[w] = classification_report(y_test, y_pred, output_dict=True)\n",
    "    RocCurveDisplay.from_estimator(classifier, X_test, y_test)\n",
    "    plt.title(f\"Weight: {round(w, 2)}\")\n",
    "    plt.savefig(f\"./ROC_{round(w, 2)}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (\"Accuracy : \", accuracy_score(y_test, y_pred))\n",
    "print(cm)\n",
    "print(classifier.coef_)\n",
    "# Hanno pi√π influenza DepTime, Distance and taxiOut\n",
    "print(np.std(X, 0)*classifier.coef_)\n",
    "# Plot ROC\n",
    "RocCurveDisplay.from_estimator(classifier, X_test, y_test)\n",
    "plt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree model\n",
    "dModel = DecisionTreeClassifier(n_jobs=-1)\n",
    "dModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = dModel.predict_proba(X_test)\n",
    "RocCurveDisplay.from_estimator(dModel, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsampling data\n",
    "num_training = 10000\n",
    "X_train_sub = X_train[:num_training]\n",
    "y_train_sub = y_train[:num_training]\n",
    "\n",
    "k_range = range(5, 11)\n",
    "scores = {}\n",
    "scores_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in tqdm(k_range):\n",
    "    kCl = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)\n",
    "    kFit = kCl.fit(X_train_sub, y_train_sub)\n",
    "    pred = kFit.predict(X_test)\n",
    "    scores[k] = pred\n",
    "    correct = (pred == y_test).sum()\n",
    "    scores_list.append(correct / y_train_sub.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_range, scores_list)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now pick the best k and train on the whole training set\n",
    "knn = KNeighborsClassifier(n_neighbors=10, n_jobs=-1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the accuracy\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0b743e3f46610aef585505bfb8ed266070dd1178baff540cb1eb86ae22f2f85"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
